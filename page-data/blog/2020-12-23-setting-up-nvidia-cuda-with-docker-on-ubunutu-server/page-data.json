{
    "componentChunkName": "component---src-pages-blog-mdx-slug-js",
    "path": "/blog/2020-12-23-setting-up-nvidia-cuda-with-docker-on-ubunutu-server/",
    "result": {"data":{"mdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"layout\": \"post\",\n  \"hidden\": true,\n  \"title\": \"Setting up Nivdia CUDA on Ubunutu server\",\n  \"date\": \"2020-12-23\",\n  \"categories\": \"CUDA Nividia MachineLearning Systems tech\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"I've been having an interest in machine learning lately and wanted to configure my own server for doing machine learning on. This tutorial will assume you have a decent grasp on the command line and that you figured out how to install ubuntu server fresh. When installing ubuntu server it will ask you if you want to install docker. If you want to say yes it didn't work for me but my installer had an error in it so maybe that's why. Just in case though this tutorial will explain how to install docker (basically it is just go to the site and follow the directions but if you just google around you can get lost).\"), mdx(\"p\", null, \"Disclaimer I'm still learning but hopefully this helps. Also this tutorial only works if you have one of the following gpus: NVIDIA TITAN V, TITAN Xp, TITAN X (Pascal), NVIDIA Quadro GV100, GP100 and P6000, NVIDIA DGX. Otherwise go \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/install/gpu\"\n  }, \"here\")), mdx(\"p\", null, \"The first step in this tutorial is to go to the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.nvidia.com/Download/index.aspx?lang=en-us\"\n  }, \"Nvidia site\"), \" and download the correct driver for your GPU and for your OS. As outlined in the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.htm\"\n  }, \"Nvidia Documentation\"), \" you can check your Nvidia card by running the following command on your server:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell{promptUser:\",\n    \"metastring\": \"lucas}{promptHost: dev.localhost}\",\n    \"lucas}{promptHost:\": true,\n    \"dev.localhost}\": true\n  }, \"    lspci | grep -i nvidia\\n\")), mdx(\"p\", null, \"You will want a relatively new GPU and you can check if it is compatible with CUDA \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://developer.nvidia.com/cuda-gpus\"\n  }, \"here\")), mdx(\"p\", null, \"Now copy the driver onto your server. I used secure copy (scp) it looked something like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \" scp lucas@192.168.0.20:~/nvidia-driver.run /Users/lucas/Desktop/NVIDIA-Linux-x86_64-450.80.02.run\\n\")), mdx(\"p\", null, \"Note that I'm on Mac and my file is on the desktop. Also note that my server ip is a lan ip and it is 192.168.0.20 (I statically configured the ip in my router so I don't have to keep finding the server address). This command will vary depending on your system.\"), mdx(\"p\", null, \"Then I logged back into the server and ran the driver but it didn't work. I forgot to disable nouveau.\"), mdx(\"p\", null, \"To disable nouveau I created a file /usr/lib/modprobe.d/blacklist-nouveau.conf with nano:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"sudo nano /usr/lib/modprobe.d/blacklist-nouveau.conf\\n\")), mdx(\"p\", null, \"Then I added the following contents (as per the documentation listed above:\\n{% highlight dockerfile %}\\nblacklist nouveau\\noptions nouveau modeset=0\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"\\nThen I ran the following command:\\n```shell\\nsudo update-initramfs -u\\n\")), mdx(\"p\", null, \"Also while I was at it I installed gcc which is a dependency of CUDA. I don't think the driver depends on it tho. And I installed make which the driver depends on.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"sudo apt install gcc\\ngcc --version\\nsudo apt install make\\n\")), mdx(\"p\", null, \"Then I ran the script again with\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"sudo sh ./nvidia-driver.run\\n\")), mdx(\"p\", null, \"Then I installed docker as the site recommends \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.docker.com/engine/install/ubuntu/\"\n  }, \"here\"), \". I had some issues with the previous install from snap (don't get me wrong snap is great when it works) but, I got those figured out.\"), mdx(\"p\", null, \"Then I installed nvidia-docker2 as per \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\"\n  }, \"here\"), \". Those commands were:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"distribution=$(. /etc/os-release;echo $ID$VERSION_ID)    && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -    && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list\\nsudo apt-get update\\nsudo apt-get install nvidia-docker2\\nsudo systemctl restart docker\\n\")), mdx(\"p\", null, \"Then the next thing to do is to install CUDA. I followed the instructions \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://developer.nvidia.com/cuda-downloads\"\n  }, \"here\"), \" for ubuntu this is kind of tricky because you can't restart after the install or else you'll end up with ubuntu desktop. I found this out the hard way and had to reinstall the server (after trying to remove x11 - aka - the desktop)\\nHere are the commands I used to install CUDA:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"wget https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda_11.2.0_460.27.04_linux.run\\nsudo sh cuda_11.2.0_460.27.04_linux.run\\nsudo apt-get autoremove\\n\")), mdx(\"p\", null, \"Note that apt-get autoremove will remove x11 and the desktop environment as well as some useful packages like the docs and such but oh well.\"), mdx(\"p\", null, \"Lastly verify your install with:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"nvidia-smi\\n\")), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/assets/2020-12-23-GPUs/nvidia-smi.png\",\n    \"alt\": \"You will see something like this\"\n  })), mdx(\"p\", null, \"Once you have CUDA installed properly you can test it out properly with docker. I followed \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://powersj.io/post/ubuntu-server-nvidia-cuda/\"\n  }, \"this\"), \" tutorial to get started. Basically you just create a Dockerfile. Something like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-dockerfile\"\n  }, \"mkdir docker\\ncd docker\\nnano Dockerfile\\n\")), mdx(\"p\", null, \"Then in the Dockerfile:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-dockerfile\"\n  }, \"FROM nvidia/cuda:11.1-base\\nCMD nvidia-smi\\n\")), mdx(\"p\", null, \"Then to build and run the file:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"docker build -t nvidia-test .\\nsudo docker run --gpus all nvidia-test\\n\")), mdx(\"p\", null, \"If you have all this working I would download tensor flow from docker with:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-shell\"\n  }, \"docker pull nvcr.io/nvidia/tensorflow:20.12-tf1-py3\\n docker run --gpus all -it --rm nvcr.io/nvidia/tensorflow:20.12-tf1-py3\\n\")), mdx(\"p\", null, \"Then once you start on your project you might want to use volumes as outlined \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow\"\n  }, \"here\"), \" Note that this build of the tensorflow in the docker container is old if you want to run the new version of tensorflow run \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Pip install --quite --upgrade tf-nightly\"), \" then your tutorials will work.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Setting up Nivdia CUDA on Ubunutu server","date":"December 23, 2020"}}},"pageContext":{"id":"060dd80a-a103-531f-8325-5195c5569d72","slug":"2020-12-23-Setting-Up-Nvidia-Cuda-with-docker-on-ubunutu-server","__params":{"slug":"2020-12-23-setting-up-nvidia-cuda-with-docker-on-ubunutu-server"}}},
    "staticQueryHashes": []}